{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "1. Over 15 million labeled high-resolution images belonging to roughly 22,000 categories. \n",
    "2. On ImageNet, it is customary to report two error rates:\n",
    "    top-1 and top-5, where the top-5 error rate is the fraction of test images for which the correct label is not among the five labels considered most probable by the model.\n",
    "3. Down-sampled the images to a fixed resolution of 256 × 256.\n",
    "4. Subtracting the mean activity over the training set from each pixel and trained our network on the (centered) raw RGB values of the pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It contains eight learned layers — five convolutional and three fully-connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relu\n",
    "\n",
    "* In terms of training time with gradient descent, Tanh and sigmoid saturating nonlinearities are much slower than the non-saturating nonlinearity f(x) = max(0, x) (ReLu).\n",
    "\n",
    "* ReLUs have the desirable property that they do not require input normalization to prevent them from saturating but applied special normality \"brightness normalization\"(check paper) after few layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlapping pooling\n",
    "\n",
    "* Pooling layers in CNNs summarize the outputs of neighboring groups of neurons in the same kernel map.\n",
    "* We generally observe during training that models with overlapping pooling find it slightly more difficult to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Architecture\n",
    "\n",
    "* the net contains eight layers with weights; the first five are convolutional and the remaining three are fullyconnected.\n",
    "* The output of the last fully-connected layer is fed to a 1000-way softmax which produces a distribution over the 1000 class labels\n",
    "\n",
    "* Two GPUs are used for parallel processing . Only 3rd conv layer uses input from both GPUs otherwise all layers get inputs from their respective GPU.\n",
    "\n",
    "* The kernels of the second, fourth, and fifth convolutional layers are connected only to those kernel maps in the previous layer which reside on the same GPU.\n",
    "\n",
    "* The kernels of the third convolutional layer are connected to all kernel maps in the second layer.\n",
    "\n",
    "* Response-normalization layers follow the first and second convolutional layers. \n",
    "\n",
    "* Max-pooling layersfollow both response-normalization layers as well as the fifth convolutional layer.\n",
    "\n",
    "* The ReLU non-linearity is applied to the output of every convolutional and fully-connected layer.\n",
    "\n",
    "* The third, fourth, and fifth convolutional layers are connected to one another without any intervening pooling or normalization layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](input/alexnet_architecture.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernal Sizes\n",
    "\n",
    "* Input Image = 224×224×3 (input)\n",
    "\n",
    "* 1st Conv Layer =  96 kernels of size 11×11×3 with a stride of 4 pixels \n",
    "* 2nd Conv Layer = 256 kernels of size 5 × 5 × 48  (48 because there are 2 GPUs having 48 and 48 inputs each)\n",
    "* 3rd Conv Layer =  384 kernels of size 3 × 3 × 256 (Third layer gets all the inputs on each GPU)\n",
    "* 4th Conv Layer = 384 kernels of size 3 × 3 × 192 (192 same as second layer)\n",
    "* 5th Conv Layer =  256 kernels of size 3 × 3 × 192 (192 same as second layer)\n",
    "* 1st FC Layer = 4096 neurons\n",
    "* 2nd FC Layer = 4096 neurons\n",
    "* 3rd FC Layer = 1000 neurons (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Overfitting\n",
    "\n",
    "#### Data Augmentation\n",
    "\n",
    "1. Generating image translations and horizontal reflections.\n",
    "\n",
    "2.  Altering the intensities of the RGB channels in training images.\n",
    "\n",
    "    * As object identity is invariant to changes in the intensity and color of the illumination.They used below method\n",
    "    \n",
    "    * Perform PCA on the set of RGB pixel values throughout the ImageNet training set.\n",
    "    * To each training image, we add multiples of the found principal components, with magnitudes proportional to the corresponding eigenvalues times a random variable drawn from a Gaussian with mean zero and standard deviation 0.1.\n",
    "    \n",
    "    \n",
    "#### Dropout\n",
    "\n",
    "* Setting to zero the output of each hidden neuron with probability 0.5.\n",
    "\n",
    "* The neurons which are “dropped out” in this way do not contribute to the forward pass and do not participate in backpropagation.\n",
    "\n",
    "* Every time an input is presented, the neural network samples a different architecture ,therefore, forced to learn more robust features that are useful in conjunction with many different random subsets of the other neurons. \n",
    "\n",
    "* At test time, we use all the neurons but multiply their outputs by 0.5, which is a reasonable approximation to taking the geometric mean of the predictive distributions produced by the exponentially-many dropout networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details of learning\n",
    "\n",
    "* Stochastic gradient descent\n",
    "* Batch size = 128\n",
    "* Momentum = 0.9\n",
    "* Weight decay = 0.0005 => weight decay here is not merely a regularizer: it reduces the model’s training error.\n",
    "* Formula =     \n",
    "                vi+1 :=   ( 0.9 * vi) − (0.0005 * alpha * wi) − (alpha *(∂L/∂w))\n",
    "\n",
    "                wi+1 := wi + vi+1\n",
    "                \n",
    "* Initialized the weights in each layer from a zero-mean Gaussian distribution with standard deviation 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

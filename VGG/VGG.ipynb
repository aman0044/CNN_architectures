{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG (Importance of depth)\n",
    "\n",
    "#### Paper link : https://arxiv.org/abs/1409.1556\n",
    "\n",
    "#### Code link : https://github.com/keras-team/keras/blob/master/keras/applications/vgg16.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This network is specially characterized by its pyramidal shape, where the bottom layers which are closer to the image are wide, whereas the top layers are deep.\n",
    "\n",
    "* As the image depicts, VGG contains subsequent convolutional layers followed by pooling layers. The pooling layers are responsible for making the layers narrower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "\n",
    "* Good for benchmarking.\n",
    "* Pre-trained networks for VGG are available freely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvatages\n",
    "\n",
    " * Takes a lot of time for training from scratch.(more than a week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preprocessing : subtracting the mean RGB value, computed on the training set, from each pixel.\n",
    "* Input size: 224 x 224\n",
    "* Receptive field size is 3 x 3 (kernel size)\n",
    "* Convolution stride is 1 pixel\n",
    "* Padding is 1 (for receptive field of 3 x 3) so we keep the same spatial resolution;\n",
    "* 5 Max pooling layers with 2 x 2 kernel and stride of 2 pixels\n",
    "* Two fully connected layers with 4096 units each;\n",
    "* Last layer is a softmax classification layer with 1000 units (representing the 1000 ImageNet classes);\n",
    "* All layers have activation function : ReLU\n",
    "* No Local Response Normalisation\n",
    "* Depth is increased with a factor of 2 after each pooling layer\n",
    "\n",
    "* In one of the configurations we also utilise 1 Ã— 1 convolution filters, which can be seen as a linear transformation of the input channels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](input/VGG_architecture.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive Field Arithmetic\n",
    "![alt text](input/receptive_field.png \"Title\")\n",
    "\n",
    "* nout = output feature map\n",
    "* jout = jump in the output feature map\n",
    "* rout = receptive field\n",
    "* sout = center position of the receptive field of the first output feature\n",
    "\n",
    "Example : 3 3x3 kernels with stride 1 are quivalent to 1 7x7 kernel in terms of receptive field but have less number of parameters. \n",
    "* Hence they have used 3x3 kernels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Training : hyper paramerters are same as Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
